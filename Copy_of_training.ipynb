{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preqon/neurosparks-gtec-hack/blob/main/Copy_of_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the original toy dataset\n",
        "# Original full dataset can be downloaded from https://scholar.cu.edu.eg/dataset_BUSI.zip\n",
        "\n",
        "!unzip Dataset_BUSI.zip"
      ],
      "metadata": {
        "id": "zd-y6M-Ccp4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF0nhQsgWDZg"
      },
      "outputs": [],
      "source": [
        "# Take Dataset_BUSI_with_GT files and\n",
        "# group them seperately into images and masks folders inside \"dataset\" folder,\n",
        "# also convert multiple tumor masks into a single tumor mask if they correspond to a single real ultrasound image\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "f = './Dataset_BUSI_with_GT/normal/'\n",
        "\n",
        "if not os.path.exists('./dataset_prep/'):\n",
        "    os.makedirs('./dataset_prep/')\n",
        "\n",
        "lowest_img_shape_0 = 10000\n",
        "lowest_img_shape_1 = 10000\n",
        "highest_img_shape_0 = 0\n",
        "highest_img_shape_1 = 0\n",
        "\n",
        "for file in os.listdir(f):\n",
        "    if 'mask' not in file:\n",
        "        f_img = f + file\n",
        "        img = cv2.imread(f_img, 0)\n",
        "\n",
        "        img_shape_0, img_shape_1 = img.shape[0], img.shape[1]\n",
        "        if lowest_img_shape_0 > img_shape_0:\n",
        "            lowest_img_shape_0 = img_shape_0\n",
        "        if lowest_img_shape_1 > img_shape_1:\n",
        "            lowest_img_shape_1 = img_shape_1\n",
        "        if highest_img_shape_0 < img_shape_0:\n",
        "            highest_img_shape_0 = img_shape_0\n",
        "        if highest_img_shape_1 < img_shape_1:\n",
        "            highest_img_shape_1 = img_shape_1\n",
        "\n",
        "        if not os.path.exists('./dataset_prep/images/'):\n",
        "            os.makedirs('./dataset_prep/images/')\n",
        "\n",
        "        filename = './dataset_prep/images/' + file\n",
        "        cv2.imwrite(filename, img)\n",
        "\n",
        "        img_mask = np.copy(img) * 0\n",
        "\n",
        "        for file_mask in os.listdir(f):\n",
        "            if ('mask' in file_mask) and (file[:-4] in file_mask):\n",
        "                img_mask = img_mask + cv2.imread(f + file_mask, 0)\n",
        "\n",
        "        if not os.path.exists('./dataset_prep/masks/'):\n",
        "            os.makedirs('./dataset_prep/masks/')\n",
        "\n",
        "        filename_mask = './dataset_prep/masks/' + file\n",
        "        cv2.imwrite(filename_mask, img_mask)\n",
        "\n",
        "f = './Dataset_BUSI_with_GT/benign/'\n",
        "\n",
        "for file in os.listdir(f):\n",
        "    if 'mask' not in file:\n",
        "        f_img = f + file\n",
        "        img = cv2.imread(f_img, 0)\n",
        "\n",
        "        img_shape_0, img_shape_1 = img.shape[0], img.shape[1]\n",
        "        if lowest_img_shape_0 > img_shape_0:\n",
        "            lowest_img_shape_0 = img_shape_0\n",
        "        if lowest_img_shape_1 > img_shape_1:\n",
        "            lowest_img_shape_1 = img_shape_1\n",
        "        if highest_img_shape_0 < img_shape_0:\n",
        "            highest_img_shape_0 = img_shape_0\n",
        "        if highest_img_shape_1 < img_shape_1:\n",
        "            highest_img_shape_1 = img_shape_1\n",
        "\n",
        "        if not os.path.exists('./dataset_prep/images/'):\n",
        "            os.makedirs('./dataset_prep/images/')\n",
        "\n",
        "        filename = './dataset_prep/images/' + file\n",
        "        cv2.imwrite(filename, img)\n",
        "\n",
        "        img_mask = np.copy(img) * 0\n",
        "\n",
        "        for file_mask in os.listdir(f):\n",
        "            if ('mask' in file_mask) and (file[:-4] in file_mask):\n",
        "                img_mask = img_mask + cv2.imread(f + file_mask, 0)\n",
        "\n",
        "        if not os.path.exists('./dataset_prep/masks/'):\n",
        "            os.makedirs('./dataset_prep/masks/')\n",
        "\n",
        "        filename_mask = './dataset_prep/masks/' + file\n",
        "        cv2.imwrite(filename_mask, img_mask)\n",
        "\n",
        "f = './Dataset_BUSI_with_GT/malignant/'\n",
        "\n",
        "for file in os.listdir(f):\n",
        "    if 'mask' not in file:\n",
        "        f_img = f + file\n",
        "        img = cv2.imread(f_img, 0)\n",
        "\n",
        "        img_shape_0, img_shape_1 = img.shape[0], img.shape[1]\n",
        "        if lowest_img_shape_0 > img_shape_0:\n",
        "            lowest_img_shape_0 = img_shape_0\n",
        "        if lowest_img_shape_1 > img_shape_1:\n",
        "            lowest_img_shape_1 = img_shape_1\n",
        "        if highest_img_shape_0 < img_shape_0:\n",
        "            highest_img_shape_0 = img_shape_0\n",
        "        if highest_img_shape_1 < img_shape_1:\n",
        "            highest_img_shape_1 = img_shape_1\n",
        "\n",
        "        if not os.path.exists('./dataset_prep/images/'):\n",
        "            os.makedirs('./dataset_prep/images/')\n",
        "\n",
        "        filename = './dataset_prep/images/' + file\n",
        "        cv2.imwrite(filename, img)\n",
        "\n",
        "        img_mask = np.copy(img) * 0\n",
        "\n",
        "        for file_mask in os.listdir(f):\n",
        "            if ('mask' in file_mask) and (file[:-4] in file_mask):\n",
        "                img_mask = img_mask + cv2.imread(f + file_mask, 0)\n",
        "\n",
        "        if not os.path.exists('./dataset_prep/masks/'):\n",
        "            os.makedirs('./dataset_prep/masks/')\n",
        "\n",
        "        filename_mask = './dataset_prep/masks/' + file\n",
        "        cv2.imwrite(filename_mask, img_mask)\n",
        "\n",
        "print(\"Smallest height value: \" + str(lowest_img_shape_0))\n",
        "print(\"Smallest width value: \" + str(lowest_img_shape_1))\n",
        "print(\"Largest height value: \" + str(highest_img_shape_0))\n",
        "print(\"Largest width value: \" + str(highest_img_shape_1))\n",
        "\n",
        "avg_img_shape_0 = (lowest_img_shape_0 + highest_img_shape_0) // 2\n",
        "avg_img_shape_1 = (lowest_img_shape_1 + highest_img_shape_1) // 2\n",
        "\n",
        "print(\"Average height value: \" + str(avg_img_shape_0))\n",
        "print(\"Average width value: \" + str(avg_img_shape_1))\n",
        "\n",
        "final_img_shape = [(avg_img_shape_0 // 4) * 4, (avg_img_shape_1 // 4) * 4]\n",
        "\n",
        "print(\"Final shape: \" + str(final_img_shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUbzvNSUWDZi"
      },
      "outputs": [],
      "source": [
        "# Generate Pseudo B-mode images from masks\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PolarPseudoBMode import generate_pseudo_b_mode\n",
        "\n",
        "input_masks_path = './dataset_prep/masks/'\n",
        "output_masks_path = './dataset_prep/stage_0/'\n",
        "\n",
        "if not os.path.exists(output_masks_path):\n",
        "    os.makedirs(output_masks_path)\n",
        "\n",
        "for file in sorted(os.listdir(input_masks_path)):\n",
        "    f_mask = input_masks_path + file\n",
        "\n",
        "    input_tensor = cv2.imread(f_mask, 0)\n",
        "\n",
        "    if file not in sorted(os.listdir(output_masks_path)):\n",
        "        output_tensor = generate_pseudo_b_mode(input_tensor, low=0.4, mid=0.0, high=0.02, f0=5e6, sigma_x=5.0, sigma_y=2.0, speckle_variance=0.01, gamma=0.06)\n",
        "\n",
        "        cv2.imwrite(output_masks_path + file, output_tensor)\n",
        "        print(\"Done: \" + file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzSr1g3zWDZj"
      },
      "outputs": [],
      "source": [
        "# Crop and pad images to convert all images to equal shape\n",
        "# Scale the images to one-fourth times their height and width\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "final_img_shape = [512, 616]\n",
        "final_img_shape = [final_img_shape[0] // 4, final_img_shape[1] // 4]\n",
        "print(\"Final shape: \" + str(final_img_shape))\n",
        "\n",
        "input_masks_path = './dataset_prep/images/'\n",
        "output_masks_path = './dataset/images/'\n",
        "\n",
        "if not os.path.exists(output_masks_path):\n",
        "    os.makedirs(output_masks_path)\n",
        "\n",
        "for file in sorted(os.listdir(input_masks_path)):\n",
        "    f_mask = input_masks_path + file\n",
        "\n",
        "    input_tensor = cv2.imread(f_mask, 0)\n",
        "    input_tensor = input_tensor[::4, ::4]\n",
        "    output_tensor = np.zeros((final_img_shape[0], final_img_shape[1]), dtype = input_tensor.dtype)\n",
        "\n",
        "    if output_tensor.shape[0] < input_tensor.shape[0]:\n",
        "        input_tensor = input_tensor[:output_tensor.shape[0], :]\n",
        "    if output_tensor.shape[1] < input_tensor.shape[1]:\n",
        "        input_tensor = input_tensor[:, ((input_tensor.shape[1] - output_tensor.shape[1]) // 2): ((input_tensor.shape[1] - output_tensor.shape[1]) // 2) + output_tensor.shape[1]]\n",
        "\n",
        "    output_tensor[:input_tensor.shape[0], ((output_tensor.shape[1] - input_tensor.shape[1]) // 2): ((output_tensor.shape[1] - input_tensor.shape[1]) // 2) + input_tensor.shape[1]] = input_tensor[:, :]\n",
        "\n",
        "    cv2.imwrite(output_masks_path + file, output_tensor)\n",
        "    cv2.imwrite(output_masks_path + file.replace(\" (\", \" f (\"), output_tensor[:, ::-1])\n",
        "\n",
        "print(\"Done: \" + output_masks_path)\n",
        "\n",
        "input_masks_path = './dataset_prep/masks/'\n",
        "output_masks_path = './dataset/masks/'\n",
        "\n",
        "if not os.path.exists(output_masks_path):\n",
        "    os.makedirs(output_masks_path)\n",
        "\n",
        "for file in sorted(os.listdir(input_masks_path)):\n",
        "    f_mask = input_masks_path + file\n",
        "\n",
        "    input_tensor = cv2.imread(f_mask, 0)\n",
        "    input_tensor = input_tensor[::4, ::4]\n",
        "    output_tensor = np.zeros((final_img_shape[0], final_img_shape[1]), dtype = input_tensor.dtype)\n",
        "\n",
        "    if output_tensor.shape[0] < input_tensor.shape[0]:\n",
        "        input_tensor = input_tensor[:output_tensor.shape[0], :]\n",
        "    if output_tensor.shape[1] < input_tensor.shape[1]:\n",
        "        input_tensor = input_tensor[:, ((input_tensor.shape[1] - output_tensor.shape[1]) // 2): ((input_tensor.shape[1] - output_tensor.shape[1]) // 2) + output_tensor.shape[1]]\n",
        "\n",
        "    output_tensor[:input_tensor.shape[0], ((output_tensor.shape[1] - input_tensor.shape[1]) // 2): ((output_tensor.shape[1] - input_tensor.shape[1]) // 2) + input_tensor.shape[1]] = input_tensor[:, :]\n",
        "\n",
        "    cv2.imwrite(output_masks_path + file, output_tensor)\n",
        "    cv2.imwrite(output_masks_path + file.replace(\" (\", \" f (\"), output_tensor[:, ::-1])\n",
        "\n",
        "print(\"Done: \" + output_masks_path)\n",
        "\n",
        "input_masks_path = './dataset_prep/stage_0/'\n",
        "output_masks_path = './dataset/stage_0/'\n",
        "\n",
        "if not os.path.exists(output_masks_path):\n",
        "    os.makedirs(output_masks_path)\n",
        "\n",
        "for file in sorted(os.listdir(input_masks_path)):\n",
        "    f_mask = input_masks_path + file\n",
        "\n",
        "    input_tensor = cv2.imread(f_mask, 0)\n",
        "    input_tensor = input_tensor[::4, ::4]\n",
        "    output_tensor = np.zeros((final_img_shape[0], final_img_shape[1]), dtype = input_tensor.dtype)\n",
        "\n",
        "    if output_tensor.shape[0] < input_tensor.shape[0]:\n",
        "        input_tensor = input_tensor[:output_tensor.shape[0], :]\n",
        "    if output_tensor.shape[1] < input_tensor.shape[1]:\n",
        "        input_tensor = input_tensor[:, ((input_tensor.shape[1] - output_tensor.shape[1]) // 2): ((input_tensor.shape[1] - output_tensor.shape[1]) // 2) + output_tensor.shape[1]]\n",
        "\n",
        "    output_tensor[:input_tensor.shape[0], ((output_tensor.shape[1] - input_tensor.shape[1]) // 2): ((output_tensor.shape[1] - input_tensor.shape[1]) // 2) + input_tensor.shape[1]] = input_tensor[:, :]\n",
        "\n",
        "    cv2.imwrite(output_masks_path + file, output_tensor)\n",
        "    cv2.imwrite(output_masks_path + file.replace(\" (\", \" f (\"), output_tensor[:, ::-1])\n",
        "\n",
        "print(\"Done: \" + output_masks_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFZargACWDZj"
      },
      "outputs": [],
      "source": [
        "# Define method for shuffling real samples and fake samples, and for setting whether gradients are required\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else torch.device('cpu'))\n",
        "\n",
        "def shuffler(real, fake):\n",
        "    y = torch.randint(0, 2, (real.size(0),), dtype=torch.float).to(device)\n",
        "\n",
        "    z1 = torch.cat([real, fake], dim=1)\n",
        "    z2 = torch.cat([fake, real], dim=1)\n",
        "\n",
        "    discriminator_input = torch.empty((0, z1.size(1), z1.size(2), z1.size(3))).to(device)\n",
        "\n",
        "    for i in range(y.size(0)):\n",
        "        if y[i].item() == 1:\n",
        "            discriminator_input = torch.cat(\n",
        "                [discriminator_input, z1[i:i + 1]], dim=0)\n",
        "        if y[i].item() == 0:\n",
        "            discriminator_input = torch.cat(\n",
        "                [discriminator_input, z2[i:i + 1]], dim=0)\n",
        "\n",
        "    return discriminator_input, y\n",
        "\n",
        "def set_requires_grad(net, requires_grad=False):\n",
        "    for param in net.parameters():\n",
        "        param.requires_grad = requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLSga7m9WDZk"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "from Dataloader import BUS_Dataset\n",
        "from Model import GeneratorModel, DiscriminatorModel\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Making the code reproducible\n",
        "\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
        "\n",
        "initial_seed = 0\n",
        "torch.manual_seed(initial_seed)\n",
        "torch.cuda.manual_seed_all(initial_seed)\n",
        "np.random.seed(initial_seed)\n",
        "random.seed(initial_seed)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "# Specifying the device and directory to save the model weights\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else torch.device('cpu'))\n",
        "save_dir = 'weights/'\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "batch_size = 4\n",
        "n_epoch = 250\n",
        "lrate=1e-4\n",
        "beta_recon = 0.9\n",
        "beta_adv = 0.1\n",
        "\n",
        "# Initialization of models\n",
        "\n",
        "gen_model = GeneratorModel(1)\n",
        "gen_model.to(device)\n",
        "\n",
        "dis_model = DiscriminatorModel(2)\n",
        "dis_model.to(device)\n",
        "\n",
        "# Defining the optimizers\n",
        "\n",
        "gen_optim = torch.optim.Adam(gen_model.parameters(), lr=lrate)\n",
        "dis_optim = torch.optim.Adam(dis_model.parameters(), lr=lrate)\n",
        "\n",
        "# Defining the losses\n",
        "\n",
        "recon_loss = nn.L1Loss().to(device)\n",
        "adv_loss = nn.BCELoss().to(device)\n",
        "\n",
        "# Initializing the datasets and dataloaders\n",
        "\n",
        "train_dataset = BUS_Dataset(base_dir=\"dataset\", mode=\"train\")\n",
        "val_dataset = BUS_Dataset(base_dir=\"dataset\", mode=\"val\")\n",
        "test_dataset = BUS_Dataset(base_dir=\"dataset\", mode=\"test\")\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "print(\"Number of samples in training dataset: \" + str(len(train_dataset)))\n",
        "print(\"Number of samples in validation dataset: \" + str(len(val_dataset)))\n",
        "print(\"Number of samples in test dataset: \" + str(len(test_dataset)))\n",
        "\n",
        "# Training loop with validation\n",
        "\n",
        "gen_model.train()\n",
        "for ep in range(n_epoch):\n",
        "    print(f'\\nEpoch: {ep}')\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    pbar = tqdm(train_dataloader)\n",
        "    for batch_idx, (x, y, f) in enumerate(pbar):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        pred_y = gen_model(x)\n",
        "\n",
        "        dis_input, dis_gt = shuffler(y, pred_y)\n",
        "        dis_output = torch.flatten(dis_model(dis_input))\n",
        "\n",
        "        set_requires_grad(dis_model, False)\n",
        "        gen_recon_loss = recon_loss(y, pred_y) * beta_recon\n",
        "        gen_adv_loss = adv_loss(dis_output, 1 - dis_gt) * beta_adv\n",
        "        gen_total_loss = gen_recon_loss + gen_adv_loss\n",
        "        gen_optim.zero_grad()\n",
        "        gen_total_loss.backward()\n",
        "        gen_optim.step()\n",
        "        set_requires_grad(dis_model, True)\n",
        "\n",
        "        set_requires_grad(gen_model, False)\n",
        "        pred_y = gen_model(x)\n",
        "        dis_input, dis_gt = shuffler(y, pred_y)\n",
        "        dis_output = torch.flatten(dis_model(dis_input))\n",
        "        dis_adv_loss = adv_loss(dis_output, dis_gt)\n",
        "        dis_optim.zero_grad()\n",
        "        dis_adv_loss.backward()\n",
        "        dis_optim.step()\n",
        "        set_requires_grad(gen_model, True)\n",
        "\n",
        "        pbar.set_postfix(loss = gen_total_loss.item())\n",
        "\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.mkdir(save_dir)\n",
        "    torch.save(gen_model.state_dict(), save_dir + f\"model_{ep:03d}.pth\")\n",
        "    print('saved model at ' + save_dir + f\"model_{ep:03d}.pth\")\n",
        "\n",
        "    pbar_val = tqdm(val_dataloader)\n",
        "\n",
        "    gen_model.eval()\n",
        "    dis_model.eval()\n",
        "    total_loss = 0.0\n",
        "    for batch_idx, (x, y, t) in enumerate(pbar_val):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        pred_y = gen_model(x)\n",
        "\n",
        "        dis_input, dis_gt = shuffler(y, pred_y)\n",
        "        dis_output = torch.flatten(dis_model(dis_input))\n",
        "\n",
        "        gen_recon_loss = recon_loss(y, pred_y) * beta_recon\n",
        "        gen_adv_loss = adv_loss(dis_output, 1 - dis_gt) * beta_adv\n",
        "        gen_total_loss = gen_recon_loss + gen_adv_loss\n",
        "\n",
        "        pbar_val.set_postfix(loss = gen_total_loss.item())\n",
        "\n",
        "        total_loss += gen_total_loss.item()\n",
        "\n",
        "    print(' Total validation loss: {:.8f}'.format(total_loss))\n",
        "\n",
        "    gen_model.train()\n",
        "    dis_model.train()\n",
        "\n",
        "print(\"\\nDONE!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the trained model weights for inference\n",
        "\n",
        "!unzip weights.zip"
      ],
      "metadata": {
        "id": "XiFm2-iLpLDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8A0hbW_WDZl"
      },
      "outputs": [],
      "source": [
        "# Infer using the trained model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "from Dataloader import BUS_Dataset\n",
        "from Model import GeneratorModel, DiscriminatorModel\n",
        "import os\n",
        "\n",
        "# Specifying the directories to load the model from and save the inference outputs\n",
        "\n",
        "save_dir = 'weights/'\n",
        "inference_folder = \"inference/\"\n",
        "if not os.path.exists(inference_folder):\n",
        "    os.makedirs(inference_folder)\n",
        "\n",
        "# Setting the device and inference loss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else torch.device('cpu'))\n",
        "batch_size = 1\n",
        "test_loss = nn.L1Loss().to(device)\n",
        "\n",
        "# Model initialization\n",
        "\n",
        "gen_model = GeneratorModel(1)\n",
        "gen_model.to(device)\n",
        "\n",
        "# Loading the trained model weights from the last epoch\n",
        "\n",
        "model_weights = sorted(os.listdir(save_dir))[-1]\n",
        "\n",
        "gen_model.load_state_dict(torch.load(f\"{save_dir}/{model_weights}\", map_location=device))\n",
        "gen_model.eval()\n",
        "print(f\"Model loaded: {model_weights}\")\n",
        "\n",
        "# Initializing test dataset and dataloader\n",
        "\n",
        "test_dataset = BUS_Dataset(base_dir=\"dataset\", mode=\"test\")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "print(len(test_dataset))\n",
        "\n",
        "pbar_test = tqdm(test_dataloader)\n",
        "\n",
        "# Inference and saving the outputs\n",
        "\n",
        "total_loss = 0.0\n",
        "for batch_idx, (x, y, t) in enumerate(pbar_test):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    pred_y = gen_model(x)\n",
        "\n",
        "    torchvision.utils.save_image(pred_y.detach().cpu(), os.path.join(inference_folder, t[0].split(\"/\")[-1][:-4] + \"_\" + model_weights + \".png\"), normalize=True, scale_each=True)\n",
        "    torchvision.utils.save_image(x.detach().cpu(), os.path.join(inference_folder, t[0].split(\"/\")[-1][:-4] + \"_\" + model_weights + \"_x.png\"), normalize=True, scale_each=True)\n",
        "    torchvision.utils.save_image(y.detach().cpu(), os.path.join(inference_folder, t[0].split(\"/\")[-1][:-4] + \"_\" + model_weights + \"_y.png\"), normalize=True, scale_each=True)\n",
        "\n",
        "    loss = test_loss(pred_y, y)\n",
        "\n",
        "    pbar_test.set_postfix(loss = loss.item())\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "print(' Total test loss: {:.8f}'.format(total_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuJKO6J-WDZl"
      },
      "outputs": [],
      "source": [
        "# Zip the inference outputs to a single zip file for downloading\n",
        "\n",
        "!zip -r inference.zip inference/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k_95FRs-fTnD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}